{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\UserData\\takuyai\\Miniconda3\\envs\\lith_nlp\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "import nltk\n",
    "from Litho.nlp_funcs import *\n",
    "from Litho.similarity import (check_similarity, match_lithcode, jaccard_similarity, \n",
    "                              calc_similarity_score, print_sim_compare, merge_similar_words)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopw2 = ['redish', 'reddish', 'red', 'black', 'blackish', 'brown', 'brownish',\n",
    "          'blue', 'blueish', 'orange', 'orangeish', 'gray', 'grey', 'grayish',\n",
    "          'greyish', 'white', 'whiteish', 'purple', 'purpleish', 'yellow',\n",
    "          'yellowish', 'green', 'greenish', 'light', 'very', 'pink','coarse',\n",
    "          'fine', 'medium', 'hard', 'soft', 'coloured', 'multicoloured',\n",
    "          'weathered', 'fractured', 'dark', 'color', 'colour', 'clean', 'cleaner']\n",
    "\n",
    "stopwords.extend(stopw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\UserData\\takuyai\\Miniconda3\\envs\\lith_nlp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()+'/'\n",
    "file = 'boresTa.csv'\n",
    "lith_data = pd.read_csv(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using output from `criteriaClassification.ipynb` to influence our list of known classes\n",
    "classified = pd.read_csv(os.path.join(path, 'classification_criteria.csv'), usecols=[9])\n",
    "\n",
    "known_classes = set([x[0] for x in classified.values.tolist()])\n",
    "\n",
    "# manually add missing class for now\n",
    "known_classes.add('quartzite')  \n",
    "\n",
    "# Sort from longest to shortest (yes, the order matters!)\n",
    "# e.g. we want to capture 'siltstone' before matching 'silt'\n",
    "known_classes = sorted(known_classes, key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(known_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common mistakes found in dataset and corrected spelling\n",
    "corrections = {\n",
    "    'caly': 'clay',\n",
    "    'claye': 'clay',\n",
    "    'clayeyy': 'clay',\n",
    "    'gravelly': 'gravel',\n",
    "    'grvl': 'gravel',\n",
    "    'silts': 'silt',\n",
    "    'silty': 'silt',\n",
    "    'siltston': 'siltstone',\n",
    "    'comapcted': 'compacted',\n",
    "    'cchoesive': 'cohesive',\n",
    "    'conglomerte': 'conglomerate',\n",
    "    'conglomate': 'conglomerate',\n",
    "    'comglomerate': 'conglomerate',\n",
    "    'comapcted': 'compacted',\n",
    "    'tospoil': 'topsoil',\n",
    "    'toposil': 'topsoil',\n",
    "    'bolders': 'boulder',\n",
    "    'bolder': 'boulder',\n",
    "    'bsalt': 'basalt',\n",
    "    # the below are needed as it gets missed when it appears next to another word\n",
    "    'colluvial': 'colluvial',\n",
    "    'lithology': 'lithology',\n",
    "    'sidertire': 'siderite'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words the spell checker gets wrong\n",
    "known_correct_words = ['coring', 'colluvial', 'silt', 'contaminents', 'aplite', 'concretion', 'igenous', 'quartzite']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_words(mixed_str, target_word):\n",
    "    return mixed_str.replace(target_word, ' {} '.format(target_word)).replace('  ', ' ').strip()\n",
    "\n",
    "def remove_extra_whitespace(sentence):\n",
    "    wordlist = sentence.split()\n",
    "    return ' '.join([w.strip() for w in wordlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_typo(word, class_list, corrections, known_correct_words, matches=None):\n",
    "    \"\"\"Recursively clean up sentences by identifying known words and corrections.\n",
    "    \n",
    "    :param word: str, string to separate\n",
    "    :param class_list: list[str], of known lithological classes\n",
    "    :param corrections: dict, a mapping of typos and corrections\n",
    "    :param matches: list[str], identified classes\n",
    "    \n",
    "    :returns: list[str], corrected string\n",
    "    \n",
    "    Example: \n",
    "    >>> class_list = ['sandstone', 'siltstone', 'slate', 'basalt', 'rock', 'caly']\n",
    "    >>> corrections = {'caly': 'clay'}\n",
    "    >>> split_words(''sandstonesiltstoneslaterockbasaltcaly', class_list, matches=[])\n",
    "    ['sandstone', 'siltstone', 'slate', 'rock', 'basalt', 'clay']\n",
    "    \n",
    "    \"\"\"\n",
    "    orig_word = word\n",
    "    word = remove_extra_whitespace(word)\n",
    "    word = ''.join([w for w in word if not w.isdigit()])  # remove numbers\n",
    "    word = ' '.join([w for w in word.split() if w not in stopwords])  # remove stopwords\n",
    "    word = remove_extra_whitespace(word)\n",
    "    \n",
    "    if matches is None:\n",
    "        matches = []\n",
    "\n",
    "    if len(word) == 0:\n",
    "        return matches\n",
    "    \n",
    "    for possible_word in class_list:\n",
    "        if possible_word in word:\n",
    "            matches.append(possible_word)\n",
    "            word = word.replace(possible_word, '')\n",
    "        \n",
    "        if len(word) == 0:\n",
    "            break\n",
    "        # End if\n",
    "    # End for\n",
    "    \n",
    "    if len(word) > 1:\n",
    "        fixed = False\n",
    "        for typo in corrections:\n",
    "            if typo in word:\n",
    "                fixed = True\n",
    "                word = word.replace(typo, ' {} '.format(corrections[typo])).replace('  ', ' ').strip()\n",
    "            # End if\n",
    "        # End for\n",
    "        \n",
    "        # Attempt match against known classes only if known misspellings fail\n",
    "        if not fixed:\n",
    "            for cls in known_classes:\n",
    "                for wd in word.split():\n",
    "                    if (wd not in known_correct_words) and calc_similarity_score(wd, cls) == 1.0:\n",
    "                        word = word.replace(wd, cls)\n",
    "                    # End if\n",
    "                # End for\n",
    "            # End for\n",
    "        # End if\n",
    "        \n",
    "        if word != orig_word:\n",
    "            word = ' '.join([wd.strip() for wd in word.split() if len(wd) > 1])  # strip single characters\n",
    "            matches = fix_typo(word, class_list, corrections, known_correct_words, matches)\n",
    "        else:\n",
    "            matches.extend(orig_word.split())\n",
    "        # End if\n",
    "    # End if\n",
    "    \n",
    "    return list(set(matches))\n",
    "# End fix_typo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sand gravel']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_typo('coarse sand and fine gravel', known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['siltstone', 'conglomerate', 'sand']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_typo('sandsiltstonecomglomerate', known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sand']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_typo('brownsand', known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soil', 'top']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_typo('topsoil', known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['basalt',\n",
       " 'sandstone',\n",
       " 'clay',\n",
       " 'rock',\n",
       " 'colluvial',\n",
       " 'slate',\n",
       " 'siltstone',\n",
       " 'ravel']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_typo('sandstonesiltstoneslaterockbasaltcalyravelcolluvial', known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strongly',\n",
       " 'clasts',\n",
       " 'jasper',\n",
       " 'lithic',\n",
       " 'calcite',\n",
       " 'poorly',\n",
       " 'rare',\n",
       " 'containing',\n",
       " 'silica',\n",
       " 'mediumg',\n",
       " 'sand']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = 'sandy clay; light brown, strongly cohesive, rare silica clasts, . light brown sandy clay, cohesive, containing silicate jasper & lithic clasts from fine sand to mediumg ravel, poorly graded, '\n",
    "tmp = ' '.join([wd for wd in tmp.split() if wd.isalnum()])\n",
    "fix_typo(tmp, known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['less',\n",
       " 'clay',\n",
       " 'subangular,',\n",
       " 'jasper',\n",
       " 'calcrete',\n",
       " 'nodules',\n",
       " 'beige',\n",
       " 'mostly',\n",
       " 'sand gravel',\n",
       " 'quartz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = 'coarse sand and fine gravel, subangular, mostly white quartz with clear quartz & jasper.  clay nodules beige less than 20%'\n",
    "fix_typo(tmp, known_classes, corrections, known_correct_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get description column as all lower case and stripping special characters\n",
    "descriptions = lith_data.Description.str.replace('\\W', '').str.lower().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tokens = {}\n",
    "\n",
    "cleaned_descriptions = []\n",
    "for idx, src_desc in enumerate(descriptions):\n",
    "    cleaned_desc = fix_typo(str(src_desc), known_classes, corrections, [])\n",
    "    cleaned_desc = remove_extra_whitespace(' '.join(list(set([wd for wd in cleaned_desc if wd in known_classes]))).strip())\n",
    "    cleaned_descriptions.append(cleaned_desc)\n",
    "# End for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2943"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(cleaned_descriptions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = zip(descriptions, cleaned_descriptions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "current_dt = datetime.datetime.now().strftime('%Y-%m-%d_%H%M%S')\n",
    "\n",
    "pd.DataFrame({'Description': descriptions, 'Extracted': cleaned_descriptions}).to_csv('{}_attempt.csv'.format(current_dt), index=None)\n",
    "pd.DataFrame({'Unique Extracted Classes': list(set(cleaned_descriptions))}).to_csv('{}_unique_descriptions.csv'.format(current_dt), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lith NLP",
   "language": "python",
   "name": "lith-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
